import cv2
import mediapipe as mp
import pyautogui

cam = cv2.VideoCapture(0)
cam.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
cam.set(cv2.CAP_PROP_FPS, 120)

hand_mesh = mp.solutions.hands.Hands(max_num_hands=1)

screen_w, screen_h = pyautogui.size()

pyautogui.FAILSAFE = False

prev_click = None

while True:
    _, frame = cam.read()

    frame = cv2.flip(frame, 1)

    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    output = hand_mesh.process(rgb_frame)

    landmark_points = output.multi_hand_landmarks

    frame_h, frame_w, _ = frame.shape

    if landmark_points:

        landmarks = landmark_points[0].landmark

        index = landmarks[8].y
        middle = landmarks[12].y
        ring = landmarks[16].y

        for id, landmark in enumerate(landmarks[1:]):
            x = int(landmark.x * frame_w)
            y = int(landmark.y * frame_h)
            cv2.circle(frame, (x, y), 3, (0, 255, 0))

        if index > middle and index > ring:
            if prev_click != 'left':
                pyautogui.click(button='left')
                prev_click = 'left'
            pyautogui.sleep(0.1)
        elif middle > index and ring > index:
            if prev_click != 'right':
                pyautogui.click(button='right')
                prev_click = 'right'
            pyautogui.sleep(0.1)
        else:
            prev_click = None

        screen_x = screen_w / frame_w * x
        screen_y = screen_h / frame_h * y
        pyautogui.moveTo(screen_x, screen_y)

    else:
        pyautogui.position()
        pyautogui.size()

    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        break

    cv2.imshow('Hand Controlled Mouse', frame)
    cv2.waitKey(1)

cam.release()
cv2.destroyAllWindows()
